<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jared E. Knowles" />


<title>Fun with merMod Objects</title>

<script src="Tutorial1-ExploringLMERobjects_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="Tutorial1-ExploringLMERobjects_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="Tutorial1-ExploringLMERobjects_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="Tutorial1-ExploringLMERobjects_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="Tutorial1-ExploringLMERobjects_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="Tutorial1-ExploringLMERobjects_files/navigation-1.1/tabsets.js"></script>
<link href="Tutorial1-ExploringLMERobjects_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="Tutorial1-ExploringLMERobjects_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Fun with merMod Objects</h1>
<h4 class="author">Jared E. Knowles</h4>
<h4 class="date">Saturday, May 17, 2014</h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>First of all, be warned, the terminology surrounding multilevel models is vastly inconsistent. For example, multilevel models themselves may be referred to as hierarchical linear models, random effects models, multilevel models, random intercept models, random slope models, or pooling models. Depending on the discipline, software used, and the academic literature many of these terms may be referring to the same general modeling strategy. In this tutorial I will attempt to provide a user guide to multilevel modeling by demonstrating how to fit multilevel models in R and by attempting to connect the model fitting procedure to commonly used terminology used regarding these models.</p>
<p>We will cover the following topics:</p>
<ul>
<li>The structure and methods of <code>merMod</code> objects</li>
<li>Extracting random effects of <code>merMod</code> objects</li>
<li>Plotting and interpreting <code>merMod</code> objects</li>
</ul>
<p>If you haven’t already, make sure you head over to the <a href="http://jaredknowles.com/journal/2013/11/25/getting-started-with-mixed-effect-models-in-r">Getting Started With Multilevel Models tutorial</a> in order to ensure you have set up your environment correctly and installed all the necessary packages. The tl;dr is that you will need:</p>
<ul>
<li>A current version of R (2.15 or greater)</li>
<li>The <code>lme4</code> package (<code>install.packages("lme4")</code>)</li>
</ul>
</div>
<div id="read-in-the-data" class="section level1">
<h1>Read in the data</h1>
<p>Multilevel models are appropriate for a particular kind of data structure where units are nested within groups (generally 5+ groups) and where we want to model the group structure of the data. For our introductory example we will start with a simple example from the <code>lme4</code> documentation and explain what the model is doing. We will use data from Jon Starkweather at the <a href="http://bayes.acs.unt.edu:8083/BayesContent/class/Jon/">University of North Texas</a>. Visit the excellent tutorial <a href="http://bayes.acs.unt.edu:8083/BayesContent/class/Jon/Benchmarks/LinearMixedModels_JDS_Dec2010.pdf">available here for more.</a></p>
<pre class="r"><code>library(lme4) # load library
library(arm) # convenience functions for regression in R
lmm.data &lt;- read.table(&quot;http://bayes.acs.unt.edu:8083/BayesContent/class/Jon/R_SC/Module9/lmm.data.txt&quot;,
                       header=TRUE, sep=&quot;,&quot;, na.strings=&quot;NA&quot;, dec=&quot;.&quot;, strip.white=TRUE)
#summary(lmm.data)
head(lmm.data)</code></pre>
<pre><code>##   id    extro     open    agree    social class school
## 1  1 63.69356 43.43306 38.02668  75.05811     d     IV
## 2  2 69.48244 46.86979 31.48957  98.12560     a     VI
## 3  3 79.74006 32.27013 40.20866 116.33897     d     VI
## 4  4 62.96674 44.40790 30.50866  90.46888     c     IV
## 5  5 64.24582 36.86337 37.43949  98.51873     d     IV
## 6  6 50.97107 46.25627 38.83196  75.21992     d      I</code></pre>
<p>Here we have data on the extroversion of subjects nested within classes and within schools.</p>
<p>Let’s understand the structure of the data a bit before we begin:</p>
<pre class="r"><code>str(lmm.data)</code></pre>
<pre><code>## &#39;data.frame&#39;:    1200 obs. of  7 variables:
##  $ id    : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ extro : num  63.7 69.5 79.7 63 64.2 ...
##  $ open  : num  43.4 46.9 32.3 44.4 36.9 ...
##  $ agree : num  38 31.5 40.2 30.5 37.4 ...
##  $ social: num  75.1 98.1 116.3 90.5 98.5 ...
##  $ class : Factor w/ 4 levels &quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;: 4 1 4 3 4 4 4 4 1 2 ...
##  $ school: Factor w/ 6 levels &quot;I&quot;,&quot;II&quot;,&quot;III&quot;,..: 4 6 6 4 4 1 3 4 3 1 ...</code></pre>
<p>Here we see we have two possible grouping variables – <code>class</code> and <code>school</code>. Let’s explore them a bit further:</p>
<pre class="r"><code>table(lmm.data$class)</code></pre>
<pre><code>## 
##   a   b   c   d 
## 300 300 300 300</code></pre>
<pre class="r"><code>table(lmm.data$school)</code></pre>
<pre><code>## 
##   I  II III  IV   V  VI 
## 200 200 200 200 200 200</code></pre>
<pre class="r"><code>table(lmm.data$class, lmm.data$school)</code></pre>
<pre><code>##    
##      I II III IV  V VI
##   a 50 50  50 50 50 50
##   b 50 50  50 50 50 50
##   c 50 50  50 50 50 50
##   d 50 50  50 50 50 50</code></pre>
<p>This is a perfectly balanced dataset. In all likelihood you aren’t working with a perfectly balanced dataset, but we’ll explore the implications for that in the future. For now, let’s plot the data a bit. Using the excellent <code>xyplot</code> function in the <code>lattice</code> package, we can explore the relationship between schools and classes across our variables.</p>
<pre class="r"><code>require(lattice)
xyplot(extro ~ open + social + agree | class, data = lmm.data, 
                 auto.key = list(x = .85, y = .035, corner = c(0, 0)), 
       layout = c(4,1), main = &quot;Extroversion by Class&quot;) </code></pre>
<p><img src="Tutorial1-ExploringLMERobjects_files/figure-html/xyplot1-1.svg" /><!-- --></p>
<p>Here we see that within classes there are clear stratifications and we also see that the <code>social</code> variable is strongly distinct from the <code>open</code> and <code>agree</code> variables. We also see that class <code>a</code> and class <code>d</code> have significantly more spread in their lowest and highest bands respectively. Let’s next plot the data by <code>school</code>.</p>
<pre class="r"><code>xyplot(extro ~ open + social + agree | school, data = lmm.data, 
                 auto.key = list(x = .85, y = .035, corner = c(0, 0)), 
       layout = c(3, 2), main = &quot;Extroversion by School&quot;) </code></pre>
<p><img src="Tutorial1-ExploringLMERobjects_files/figure-html/xyplot2-1.svg" /><!-- --></p>
<p>By school we see that students are tightly grouped, but that school <code>I</code> and school <code>VI</code> show substantially more dispersion than the other schools. The same pattern among our predictors holds between schools as it did between classes. Let’s put it all together:</p>
<pre class="r"><code>xyplot(extro ~ open + social + agree | school + class, data = lmm.data, 
                 auto.key = list(x = .85, y = .035, corner = c(0, 0)), 
       main = &quot;Extroversion by School and Class&quot;) </code></pre>
<p><img src="Tutorial1-ExploringLMERobjects_files/figure-html/xyplot3-1.svg" /><!-- --></p>
<p>Here we can see that school and class seem to closely differentiate the relationship between our predictors and extroversion.</p>
<div id="exploring-the-internals-of-a-mermod-object" class="section level2">
<h2>Exploring the Internals of a merMod Object</h2>
<p>In the last tutorial we fit a series of random intercept models to our nested data. We will examine the <code>lmerMod</code> object produced when we fit this model in much more depth in order to understand how to work with mixed effect models in R. We start by fitting a the basic example below grouped by class:</p>
<pre class="r"><code>MLexamp1 &lt;- lmer(extro ~ open + agree + social + (1|school), data=lmm.data)
class(MLexamp1)</code></pre>
<pre><code>## [1] &quot;lmerMod&quot;
## attr(,&quot;package&quot;)
## [1] &quot;lme4&quot;</code></pre>
<p>First, we see that <code>MLexamp1</code> is now an R object of the class <code>lmerMod</code>. This <code>lmerMod</code> object is an <strong>S4</strong> class, and to explore its structure, we use <code>slotNames</code>:</p>
<pre class="r"><code>slotNames(MLexamp1)</code></pre>
<pre><code>##  [1] &quot;resp&quot;    &quot;Gp&quot;      &quot;call&quot;    &quot;frame&quot;   &quot;flist&quot;   &quot;cnms&quot;    &quot;lower&quot;   &quot;theta&quot;   &quot;beta&quot;   
## [10] &quot;u&quot;       &quot;devcomp&quot; &quot;pp&quot;      &quot;optinfo&quot;</code></pre>
<pre class="r"><code>#showMethods(classes=&quot;lmerMod&quot;)</code></pre>
<p>Within the <code>lmerMod</code> object we see a number of objects that we may wish to explore. To look at any of these, we can simply type <code>MLexamp1@</code> and then the slot name itself. For example:</p>
<pre class="r"><code>MLexamp1@call # returns the model call</code></pre>
<pre><code>## lmer(formula = extro ~ open + agree + social + (1 | school), 
##     data = lmm.data)</code></pre>
<pre class="r"><code>MLexamp1@beta # returns the betas</code></pre>
<pre><code>## [1] 59.116514199  0.009750941  0.027788360 -0.002151446</code></pre>
<pre class="r"><code>class(MLexamp1@frame) # returns the class for the frame slot</code></pre>
<pre><code>## [1] &quot;data.frame&quot;</code></pre>
<pre class="r"><code>head(MLexamp1@frame) # returns the model frame</code></pre>
<pre><code>##      extro     open    agree    social school
## 1 63.69356 43.43306 38.02668  75.05811     IV
## 2 69.48244 46.86979 31.48957  98.12560     VI
## 3 79.74006 32.27013 40.20866 116.33897     VI
## 4 62.96674 44.40790 30.50866  90.46888     IV
## 5 64.24582 36.86337 37.43949  98.51873     IV
## 6 50.97107 46.25627 38.83196  75.21992      I</code></pre>
<p>The <code>merMod</code> object has a number of methods available – too many to enumerate here. But, we will go over some of the more common in the list below:</p>
<pre class="r"><code>methods(class = &quot;merMod&quot;)</code></pre>
<pre><code>##  [1] anova          as.function    coef           confint        cooks.distance deviance      
##  [7] df.residual    display        drop1          extractAIC     extractDIC     family        
## [13] fitted         fixef          formula        getL           getME          hatvalues     
## [19] influence      isGLMM         isLMM          isNLMM         isREML         logLik        
## [25] mcsamp         model.frame    model.matrix   ngrps          nobs           plot          
## [31] predict        print          profile        qqmath         ranef          refit         
## [37] refitML        rePCA          residuals      rstudent       se.coef        show          
## [43] sigma.hat      sigma          sim            simulate       standardize    summary       
## [49] terms          update         VarCorr        vcov           weights       
## see &#39;?methods&#39; for accessing help and source code</code></pre>
<p>A common need is to extract the fixed effects from a <code>merMod</code> object. <code>fixef</code> extracts a named numeric vector of the fixed effects, which is handy.</p>
<pre class="r"><code>fixef(MLexamp1)</code></pre>
<pre><code>##  (Intercept)         open        agree       social 
## 59.116514199  0.009750941  0.027788360 -0.002151446</code></pre>
<p>If you want to get a sense of the p-values or statistical significance of these parameters, first consult the <code>lme4</code> help by running <code>?mcmcsamp</code> for a rundown of various ways of doing this. One convenient way built into the package is:</p>
<pre class="r"><code>confint(MLexamp1, level = 0.99)</code></pre>
<pre><code>##                   0.5 %      99.5 %
## .sig01       4.91840325 23.88757695
## .sigma       2.53286648  2.81455985
## (Intercept) 46.27750884 71.95609747
## open        -0.02464506  0.04414924
## agree       -0.01163700  0.06721354
## social      -0.01492690  0.01062510</code></pre>
<p>From here we can see first that our fixed effect parameters overlap 0 indicating no evidence of an effect. We can also see that <code>.sig01</code>, which is our estimate of the variability in the random effect, is very large and very widely defined. This indicates we may have a lack of precision between our groups - either because the group effect is small between groups, we have too few groups to get a more precise estimate, we have too few units within each group, or a combination of all of the above.</p>
<p>Another common need is to extract the residual standard error, which is necessary for calculating effect sizes. To get a named vector of the residual standard error:</p>
<pre class="r"><code>sigma(MLexamp1)</code></pre>
<pre><code>## [1] 2.670886</code></pre>
<p>For example, it is common practice in education research to standardize fixed effects into “effect sizes” by dividing the fixed effect paramters by the residual standard error, which can be accomplished in <code>lme4</code> easily:</p>
<pre class="r"><code>fixef(MLexamp1) / sigma(MLexamp1)</code></pre>
<pre><code>##   (Intercept)          open         agree        social 
## 22.1336707437  0.0036508262  0.0104041726 -0.0008055176</code></pre>
<p>From this, we can see that our predictors of openness, agreeableness and social are virtually useless in predicting extroversion – as our plots showed. Let’s turn our attention to the random effects next.</p>
</div>
<div id="explore-group-variation-and-random-effects" class="section level2">
<h2>Explore Group Variation and Random Effects</h2>
<p>In all likelihood you fit a mixed-effect model because you are directly interested in the group-level variation in your model. It is not immediately clear how to explore this group level variation from the results of <code>summary.merMod</code>. What we get from this output is the variance and the standard deviation of the group effect, but we do not get effects for individual groups. This is where the <code>ranef</code> function comes in handy.</p>
<pre class="r"><code>ranef(MLexamp1)</code></pre>
<pre><code>## $school
##     (Intercept)
## I    -14.090991
## II    -6.183368
## III   -1.970700
## IV     1.965938
## V      6.330710
## VI    13.948412
## 
## with conditional variances for &quot;school&quot;</code></pre>
<p>Running the <code>ranef</code> function gives us the intercepts for each school, but not much additional information – for example the precision of these estimates. To do that, we need some additional commands:</p>
<pre class="r"><code>re1 &lt;- ranef(MLexamp1, condVar=TRUE) # save the ranef.mer object
class(re1)</code></pre>
<pre><code>## [1] &quot;ranef.mer&quot;</code></pre>
<pre class="r"><code>attr(re1[[1]], which = &quot;postVar&quot;)</code></pre>
<pre><code>## , , 1
## 
##           [,1]
## [1,] 0.0356549
## 
## , , 2
## 
##           [,1]
## [1,] 0.0356549
## 
## , , 3
## 
##           [,1]
## [1,] 0.0356549
## 
## , , 4
## 
##           [,1]
## [1,] 0.0356549
## 
## , , 5
## 
##           [,1]
## [1,] 0.0356549
## 
## , , 6
## 
##           [,1]
## [1,] 0.0356549</code></pre>
<p>The <code>ranef.mer</code> object is a list which contains a data.frame for each group level. The dataframe contains the random effects for each group (here we only have an intercept for each school). When we ask <code>lme4</code> for the conditional variance of the random effects it is stored in an <code>attribute</code> of those dataframes as a list of variance-covariance matrices.</p>
<p>This structure is indeed <em>complicated</em>, but it is powerful as it allows for nested, grouped, and cross-level random effects. Also, the creators of <code>lme4</code> have provided users with some simple shortcuts to get what they are really interested in out of a <code>ranef.mer</code> object.</p>
<pre class="r"><code>re1 &lt;- ranef(MLexamp1, condVar=TRUE, whichel = &quot;school&quot;)
print(re1)</code></pre>
<pre><code>## $school
##     (Intercept)
## I    -14.090991
## II    -6.183368
## III   -1.970700
## IV     1.965938
## V      6.330710
## VI    13.948412
## 
## with conditional variances for &quot;school&quot;</code></pre>
<pre class="r"><code>dotplot(re1)</code></pre>
<pre><code>## $school</code></pre>
<p><img src="Tutorial1-ExploringLMERobjects_files/figure-html/ranef3-1.svg" /><!-- --></p>
<p>This graphic shows a <code>dotplot</code> of the random effect terms, also known as a caterpillar plot. Here you can clearly see the effects of each school on <code>extroversion</code> as well as their standard errors to help identify how distinct the random effects are from one another. Interpreting random effects is notably tricky, but for assistance I would recommend looking at a few of these resources:</p>
<ul>
<li>Gelman and Hill 2006 - <a href="http://www.stat.columbia.edu/~gelman/arm/">Data Analysis Using Regression and Multilevel/Hierarchical Techniques</a></li>
<li>John Fox - An R Compantion to Applied Regression <a href="http://socserv.mcmaster.ca/jfox/Books/Companion-1E/appendix-mixed-models.pdf">web appendix</a></li>
</ul>
</div>
<div id="using-simulation-and-plots-to-explore-random-effects" class="section level2">
<h2>Using Simulation and Plots to Explore Random Effects</h2>
<p>A common econometric approach is to create what are known as <strong>empirical Bayes</strong> estimates of the group-level terms. Unfortunately there is not much agreement about what constitutes a proper standard error for the random effect terms or even how to consistently define <strong>empirical Bayes</strong> estimates.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> However, in R there are a few additional ways to get estimates of the random effects that provide the user with information about the relative sizes of the effects for each unit and the precision in that estimate. To do this, we use the <code>sim</code> function in the <code>arm</code> package.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<pre class="r"><code># A function to extract simulated estimates of random effect paramaters from 
# lme4 objects using the sim function in arm
# whichel = the character for the name of the grouping effect to extract estimates for 
# nsims = the number of simulations to pass to sim
# x = model object
REsim &lt;- function(x, whichel=NULL, nsims){
  require(plyr)
  mysim &lt;- sim(x, n.sims = nsims)
  if(missing(whichel)){
    dat &lt;- plyr::adply(mysim@ranef[[1]], c(2, 3), plyr::each(c(mean, median, sd)))
    warning(&quot;Only returning 1st random effect because whichel not specified&quot;)
  } else{
    dat &lt;- plyr::adply(mysim@ranef[[whichel]], c(2, 3), plyr::each(c(mean, median, sd)))
  }
  return(dat)
}

REsim(MLexamp1, whichel = &quot;school&quot;, nsims = 1000)</code></pre>
<pre><code>##    X1          X2       mean     median       sd
## 1   I (Intercept) -14.088205 -14.287477 3.923270
## 2  II (Intercept)  -6.183570  -6.369473 3.937168
## 3 III (Intercept)  -1.956252  -2.078317 3.925270
## 4  IV (Intercept)   1.968866   1.843241 3.930132
## 5   V (Intercept)   6.344076   6.142423 3.925949
## 6  VI (Intercept)  13.954781  13.770879 3.919504</code></pre>
<p>The <code>REsim</code> function returns for each school the level name <code>X1</code>, the estimate name, <code>X2</code>, the mean of the estimated values, the median, and the standard deviation of the estimates.</p>
<p>Another convenience function can help us plot these results to see how they compare to the results of <code>dotplot</code>:</p>
<pre class="r"><code># Dat = results of REsim
# scale = factor to multiply sd by
# var = character of &quot;mean&quot; or &quot;median&quot;
# sd = character of &quot;sd&quot;
plotREsim &lt;- function(dat, scale, var, sd){
  require(eeptools)
  dat[, sd] &lt;- dat[, sd] * scale
  dat[, &quot;ymax&quot;] &lt;- dat[, var] + dat[, sd] 
  dat[, &quot;ymin&quot;] &lt;- dat[, var] - dat[, sd] 
  dat[order(dat[, var]), &quot;id&quot;] &lt;- c(1:nrow(dat))
  ggplot(dat, aes_string(x = &quot;id&quot;, y = var, ymax = &quot;ymax&quot;, 
                         ymin = &quot;ymin&quot;)) + 
    geom_pointrange() + theme_dpi() + 
    labs(x = &quot;Group&quot;, y = &quot;Effect Range&quot;, title = &quot;Effect Ranges&quot;) + 
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          axis.text.x = element_blank(), axis.ticks.x = element_blank()) + 
    geom_hline(yintercept = 0, color = I(&quot;red&quot;), size = I(1.1))
}

plotREsim(REsim(MLexamp1, whichel = &quot;school&quot;, nsims = 1000), scale = 1.2, 
          var = &quot;mean&quot;, sd = &quot;sd&quot;)</code></pre>
<p><img src="Tutorial1-ExploringLMERobjects_files/figure-html/ebplot-1.svg" /><!-- --></p>
<p>This presents a more conservative view of the variation between random effect components. Depending on how your data was collected and your research question, alternative ways of estimating these effect sizes are possible. However, proceed with caution.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>Another approach recommended by the authors of <code>lme4</code> involves the <code>RLRsim</code> package. Using this package we can test whether or not inclusion of the random effects improves model fit and we can evaluate the p-value of additional random effect terms using a likelihood ratio test based on simulation.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<pre class="r"><code>library(RLRsim)
m0 &lt;- lm(extro ~ agree + open + social, data =lmm.data) # fit the null model
exactLRT(m = MLexamp1, m0 = m0)</code></pre>
<pre><code>## 
##  simulated finite sample distribution of LRT. (p-value based on 10000 simulated values)
## 
## data:  
## LRT = 2957.7, p-value &lt; 2.2e-16</code></pre>
<p>Here <code>exactLRT</code> issues a warning because we originally fit the model with REML instead of full maximum likelihood. Fortunately, the <code>refitML</code> function in <code>lme4</code> allows us to easily refit our model using full maximum likelihood to conduct an exact test easily.</p>
<pre class="r"><code>mA &lt;- refitML(MLexamp1)
exactLRT(m= mA, m0 = m0)</code></pre>
<pre><code>## 
##  simulated finite sample distribution of LRT. (p-value based on 10000 simulated values)
## 
## data:  
## LRT = 2957.8, p-value &lt; 2.2e-16</code></pre>
<p>Here we can see that the inclusion of our grouping variable is significant, even though the effect of each individual group may be substantively small and/or imprecisely measured. This is important in understanding the correct specification of the model. Our next tutorial will cover specification tests like this in more detail.</p>
</div>
<div id="what-do-random-effects-matter" class="section level2">
<h2>What do Random Effects Matter?</h2>
<p>How do interpret the <em>substantive</em> impact of our random effects? This is often critical in observation work trying to use a multilevel structure to understand the impact that the grouping can have on the individual observation. To do this we select 12 random cases and then we simulate their predicted value of <code>extro</code> if they were placed in each of the 6 schools. Note, that this is a very simple simulation just using the mean of the fixed effect and the conditional mode of the random effect and not replicating or sampling to get a sense of the variability. This will be left as an exercise to the reader and/or a future tutorial!</p>
<pre class="r"><code># Simulate
# Let&#39;s create 12 cases of students
# 
#sample some rows
simX &lt;- sample(lmm.data$id, 12)
simX &lt;- lmm.data[lmm.data$id %in% simX, c(3:5)] # get their data
# add an intercept
simX[, &quot;Intercept&quot;] &lt;- 1
simX &lt;- simX[, c(4, 1:3)] # reorder
simRE &lt;- REsim(MLexamp1, whichel = &quot;school&quot;, nsims = 1000) # simulate randome effects
simX$case &lt;- row.names(simX) # create a case ID
# expand a grid of case IDs by schools
simDat &lt;- expand.grid(case = row.names(simX), school = levels(lmm.data$school)) 
simDat &lt;- merge(simX, simDat) # merge in the data
# Create the fixed effect predictor
simDat[, &quot;fepred&quot;] &lt;- (simDat[, 2] * fixef(MLexamp1)[1]) + (simDat[, 3] * fixef(MLexamp1)[2]) +
          (simDat[, 4] * fixef(MLexamp1)[3]) + (simDat[, 5] * fixef(MLexamp1)[4])
# Add the school effects
simDat &lt;- merge(simDat, simRE[, c(1, 3)], by.x = &quot;school&quot;, by.y=&quot;X1&quot;)
simDat$yhat &lt;- simDat$fepred + simDat$mean # add the school specific intercept</code></pre>
<p>Now that we have set up a simulated dataframe, let’s plot it, first by case:</p>
<pre class="r"><code>qplot(school, yhat, data = simDat) + facet_wrap(~case) + theme_dpi()</code></pre>
<p><img src="Tutorial1-ExploringLMERobjects_files/figure-html/bycaseplot-1.svg" /><!-- --></p>
<p>This plot shows us that within each plot, representing a case, there is tremendous variation by school. So, moving each student into a different school has large effects on the extroversion score. But, does each case vary at each school?</p>
<pre class="r"><code>qplot(case, yhat, data = simDat) + facet_wrap(~school) + theme_dpi() + 
  theme(axis.text.x = element_blank())</code></pre>
<p><img src="Tutorial1-ExploringLMERobjects_files/figure-html/byschool-1.svg" /><!-- --></p>
<p>Here we can clearly see that within each school the cases are relatively the same indicating that the group effect is larger than the individual effects.</p>
<p>These plots are useful in demonstrating the relative importance of group and individual effects in a substantive fashion. Even more can be done to make the the graphs more informative, such as placing references to the total variability of the outcome and also looking at the distance moving groups moves each observation from its true value.</p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p><code>lme4</code> provides a very powerful object-oriented toolset for dealing with mixed effect models in R. Understanding model fit and confidence intervals of <code>lme4</code> objects requires some diligent research and the use of a variety of functions and extensions of <code>lme4</code> itself. In our next tutorial we will explore how to identify a proper specification of a random-effect model and Bayesian extensions of the <code>lme4</code> framework for difficult to specify models. We will also explore the generalized linear model framework and the <code>glmer</code> function for generalized linear modeling with multi-levels.</p>
</div>
<div id="appendix" class="section level1">
<h1>Appendix</h1>
<pre class="r"><code>print(sessionInfo(),locale=FALSE)</code></pre>
<pre><code>## R version 3.5.3 (2019-03-11)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 17134)
## 
## Matrix products: default
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] RLRsim_3.1-3    eeptools_1.2.2  ggplot2_3.1.1   plyr_1.8.4      lattice_0.20-38 arm_1.10-1     
##  [7] MASS_7.3-51.4   lme4_1.1-21     Matrix_1.2-17   knitr_1.22     
## 
## loaded via a namespace (and not attached):
##  [1] zoo_1.8-5         tidyselect_0.2.5  xfun_0.6          purrr_0.3.2       splines_3.5.3    
##  [6] colorspace_1.4-1  htmltools_0.3.6   yaml_2.2.0        mgcv_1.8-28       rlang_0.3.4      
## [11] nloptr_1.2.1      pillar_1.3.1      foreign_0.8-71    glue_1.3.1        withr_2.1.2      
## [16] sp_1.3-1          stringr_1.4.0     munsell_0.5.0     gtable_0.3.0      coda_0.19-2      
## [21] evaluate_0.13     labeling_0.3      maptools_0.9-5    lmtest_0.9-37     vcd_1.4-4        
## [26] Rcpp_1.0.1        scales_1.0.0      abind_1.4-5       digest_0.6.18     stringi_1.4.3    
## [31] dplyr_0.8.0.1     grid_3.5.3        tools_3.5.3       magrittr_1.5      lazyeval_0.2.2   
## [36] tibble_2.1.1      crayon_1.3.4      pkgconfig_2.0.2   data.table_1.12.2 assertthat_0.2.1 
## [41] minqa_1.2.4       rmarkdown_1.12    R6_2.4.0          boot_1.3-22       nlme_3.1-139     
## [46] compiler_3.5.3</code></pre>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>[See message from <code>lme4</code> co-author Doug Bates on this subject]. (<a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/002984.html" class="uri">https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/002984.html</a>)<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Andrew Gelman and Yu-Sung Su (2014). arm: Data Analysis Using Regression and Multilevel/Hierarchical Models. R package version 1.7-03. <a href="http://CRAN.R-project.org/package=arm" class="uri">http://CRAN.R-project.org/package=arm</a><a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p><a href="http://glmm.wikidot.com/faq">WikiDot FAQ from the R Mixed Models Mailing List</a><a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>There are also an extensive series of references available in the <code>References</code> section of the help by running <code>?exactLRT</code> and <code>?exactRLRT</code>.<a href="#fnref4" class="footnote-back">↩</a></p></li>
</ol>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
